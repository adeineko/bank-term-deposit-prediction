{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:24.316255Z",
     "start_time": "2024-10-17T11:13:24.307254Z"
    }
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier  # Importing XGBClassifier\n",
    "import lightgbm as lgb  # Importing LightGBM\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:24.362259Z",
     "start_time": "2024-10-17T11:13:24.319261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../dataset/updated_bank.csv\");df"
   ],
   "id": "11c5dfa9ae1008dc",
   "outputs": [
    {
     "data": {
      "text/plain": "      age           job   marital  education default  balance housing loan  \\\n0      30    unemployed   married    primary      no   1787.0      no   no   \n1      30    management   married   tertiary      no   1476.0     yes  yes   \n2      59   blue-collar   married  secondary      no      0.0     yes   no   \n3      39    technician   married  secondary      no    147.0     yes   no   \n4      41  entrepreneur   married   tertiary      no    221.0     yes   no   \n...   ...           ...       ...        ...     ...      ...     ...  ...   \n2398   33      services   married  secondary      no    288.0     yes   no   \n2399   42        admin.   married    unknown      no    642.0     yes  yes   \n2400   36    technician  divorced  secondary      no    566.0     yes   no   \n2401   49   blue-collar   married  secondary      no    322.0      no   no   \n2402   33      services   married  secondary      no   -333.0     yes   no   \n\n      day month  duration  campaign   y  contact_cellular  contact_telephone  \\\n0      19   oct        79         1  no              True              False   \n1       3   jun       199         4  no             False              False   \n2       5   may       226         1  no             False              False   \n3       6   may       151         2  no              True              False   \n4      14   may        57         2  no             False              False   \n...   ...   ...       ...       ...  ..               ...                ...   \n2398   17   apr       306         3  no              True              False   \n2399   16   may       509         2  no             False              False   \n2400   20   may       129         2  no             False              False   \n2401   14   aug       356         2  no              True              False   \n2402   30   jul       264         5  no              True              False   \n\n      contact_unknown  duration_contact_cellular  duration_contact_telephone  \\\n0               False                         79                           0   \n1                True                          0                           0   \n2                True                          0                           0   \n3               False                        151                           0   \n4                True                          0                           0   \n...               ...                        ...                         ...   \n2398            False                        306                           0   \n2399             True                          0                           0   \n2400             True                          0                           0   \n2401            False                        356                           0   \n2402            False                        264                           0   \n\n      duration_contact_unknown  above_median_duration  \n0                            0                      0  \n1                          199                      1  \n2                          226                      1  \n3                            0                      0  \n4                           57                      0  \n...                        ...                    ...  \n2398                         0                      1  \n2399                       509                      1  \n2400                       129                      0  \n2401                         0                      1  \n2402                         0                      1  \n\n[2403 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>y</th>\n      <th>contact_cellular</th>\n      <th>contact_telephone</th>\n      <th>contact_unknown</th>\n      <th>duration_contact_cellular</th>\n      <th>duration_contact_telephone</th>\n      <th>duration_contact_unknown</th>\n      <th>above_median_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>unemployed</td>\n      <td>married</td>\n      <td>primary</td>\n      <td>no</td>\n      <td>1787.0</td>\n      <td>no</td>\n      <td>no</td>\n      <td>19</td>\n      <td>oct</td>\n      <td>79</td>\n      <td>1</td>\n      <td>no</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>79</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1476.0</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>3</td>\n      <td>jun</td>\n      <td>199</td>\n      <td>4</td>\n      <td>no</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>199</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0.0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>5</td>\n      <td>may</td>\n      <td>226</td>\n      <td>1</td>\n      <td>no</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>226</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>39</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>147.0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>6</td>\n      <td>may</td>\n      <td>151</td>\n      <td>2</td>\n      <td>no</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>151</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n      <td>entrepreneur</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>221.0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>14</td>\n      <td>may</td>\n      <td>57</td>\n      <td>2</td>\n      <td>no</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>57</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2398</th>\n      <td>33</td>\n      <td>services</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>288.0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>17</td>\n      <td>apr</td>\n      <td>306</td>\n      <td>3</td>\n      <td>no</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>306</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2399</th>\n      <td>42</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>642.0</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>16</td>\n      <td>may</td>\n      <td>509</td>\n      <td>2</td>\n      <td>no</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>509</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2400</th>\n      <td>36</td>\n      <td>technician</td>\n      <td>divorced</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>566.0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>20</td>\n      <td>may</td>\n      <td>129</td>\n      <td>2</td>\n      <td>no</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>129</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2401</th>\n      <td>49</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>322.0</td>\n      <td>no</td>\n      <td>no</td>\n      <td>14</td>\n      <td>aug</td>\n      <td>356</td>\n      <td>2</td>\n      <td>no</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>356</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2402</th>\n      <td>33</td>\n      <td>services</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>-333.0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>30</td>\n      <td>jul</td>\n      <td>264</td>\n      <td>5</td>\n      <td>no</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>264</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2403 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:24.409832Z",
     "start_time": "2024-10-17T11:13:24.364262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df.drop(\"y\", axis=1);\n",
    "y = df[\"y\"]\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    X[column] = label_enc.fit_transform(X[column])\n",
    "    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ],
   "id": "67ee2cdcf1cfb838",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:24.894900Z",
     "start_time": "2024-10-17T11:13:24.412833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model 1: Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "conf_matrix_random_forest = confusion_matrix(y_test, y_pred_rf);conf_matrix_random_forest"
   ],
   "id": "a9d76bfbd7b65ff1",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[683,   4],\n       [ 33,   1]], dtype=int64)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:24.988635Z",
     "start_time": "2024-10-17T11:13:24.908906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "report_random_forest = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(report_random_forest)"
   ],
   "id": "f3665796e4665586",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.95      0.99      0.97       687\n",
      "         yes       0.20      0.03      0.05        34\n",
      "\n",
      "    accuracy                           0.95       721\n",
      "   macro avg       0.58      0.51      0.51       721\n",
      "weighted avg       0.92      0.95      0.93       721\n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:25.548002Z",
     "start_time": "2024-10-17T11:13:24.991634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model 2: Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "conf_matrix_gradient_boosting = confusion_matrix(y_test, y_pred_gb);conf_matrix_gradient_boosting"
   ],
   "id": "b52fba68186b1273",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[680,   7],\n       [ 31,   3]], dtype=int64)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:25.594311Z",
     "start_time": "2024-10-17T11:13:25.550980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "report_gradient_boosting = classification_report(y_test, y_pred_gb)\n",
    "\n",
    "print(report_gradient_boosting)"
   ],
   "id": "e021b898e8686102",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.99      0.97       687\n",
      "         yes       0.30      0.09      0.14        34\n",
      "\n",
      "    accuracy                           0.95       721\n",
      "   macro avg       0.63      0.54      0.55       721\n",
      "weighted avg       0.93      0.95      0.93       721\n",
      "\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.95      0.96       687\n",
      "         yes       0.22      0.26      0.24        34\n",
      "\n",
      "    accuracy                           0.92       721\n",
      "   macro avg       0.59      0.61      0.60       721\n",
      "weighted avg       0.93      0.92      0.92       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "conf_matrix_decision_tree = confusion_matrix(y_test, y_pred_dt)\n",
    "report_decision_tree = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Classifier Report:\")\n",
    "print(report_decision_tree)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.99      0.97       687\n",
      "         yes       0.25      0.06      0.10        34\n",
      "\n",
      "    accuracy                           0.95       721\n",
      "   macro avg       0.60      0.53      0.53       721\n",
      "weighted avg       0.92      0.95      0.93       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model)\n",
    "    ],\n",
    "    voting='hard'  # Use 'soft' for probabilistic voting if desired\n",
    ")\n",
    "\n",
    "# Fit the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the Voting Classifier\n",
    "conf_matrix_voting = confusion_matrix(y_test, y_pred_voting)\n",
    "report_voting = classification_report(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Voting Classifier Report:\")\n",
    "print(report_voting)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.99      0.97       687\n",
      "         yes       0.25      0.06      0.10        34\n",
      "\n",
      "    accuracy                           0.95       721\n",
      "   macro avg       0.60      0.53      0.53       721\n",
      "weighted avg       0.92      0.95      0.93       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()  # Meta-learner\n",
    ")\n",
    "\n",
    "# Fit the Stacking Classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the Stacking Classifier\n",
    "conf_matrix_stacking = confusion_matrix(y_test, y_pred_stacking)\n",
    "report_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "print(\"Stacking Classifier Report:\")\n",
    "print(report_stacking)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.88      0.93       687\n",
      "         yes       0.18      0.53      0.27        34\n",
      "\n",
      "    accuracy                           0.87       721\n",
      "   macro avg       0.58      0.71      0.60       721\n",
      "weighted avg       0.94      0.87      0.89       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"../dataset/updated_bank.csv\")\n",
    "X = df.drop(\"y\", axis=1)\n",
    "y = df[\"y\"]\n",
    "\n",
    "# Label Encoding for categorical features\n",
    "label_enc = LabelEncoder()\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    X[column] = label_enc.fit_transform(X[column])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance using SMOTE combined with ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_res, y_train_res = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize models with class weights\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "dt_model = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "log_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "\n",
    "# Voting Classifier as an alternative ensemble method\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model),\n",
    "        ('log', log_model)\n",
    "    ],\n",
    "    voting='soft'  # Using soft voting to improve performance\n",
    ")\n",
    "\n",
    "# Fit the Voting Classifier\n",
    "voting_clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the Voting Classifier\n",
    "print(\"Voting Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93       687\n",
      "           1       0.17      0.44      0.24        34\n",
      "\n",
      "    accuracy                           0.87       721\n",
      "   macro avg       0.57      0.67      0.59       721\n",
      "weighted avg       0.93      0.87      0.90       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert boolean columns to integer (0 and 1)\n",
    "X['contact_cellular'] = X['contact_cellular'].astype(int)\n",
    "X['contact_telephone'] = X['contact_telephone'].astype(int)\n",
    "X['contact_unknown'] = X['contact_unknown'].astype(int)\n",
    "\n",
    "# Label Encoding for categorical features in X (features)\n",
    "label_enc = LabelEncoder()\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    X[column] = label_enc.fit_transform(X[column])\n",
    "\n",
    "# Label encode the target variable y, if it's categorical (e.g., 'yes', 'no')\n",
    "if y.dtype == 'object':\n",
    "    y = label_enc.fit_transform(y)\n",
    "\n",
    "# Split the dataset after ensuring it's numeric\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance using SMOTE combined with ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_res, y_train_res = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the XGBoost model with scale_pos_weight to handle class imbalance\n",
    "pos_class_weight = (len(y_train_res) - sum(y_train_res)) / sum(y_train_res)\n",
    "xgb_model = XGBClassifier(random_state=42, scale_pos_weight=pos_class_weight)\n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1595, number of negative: 1287\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3256\n",
      "[LightGBM] [Info] Number of data points in the train set: 2882, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "LightGBM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.92      0.95       687\n",
      "         yes       0.20      0.38      0.26        34\n",
      "\n",
      "    accuracy                           0.90       721\n",
      "   macro avg       0.58      0.65      0.60       721\n",
      "weighted avg       0.93      0.90      0.91       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the LightGBM model with class_weight='balanced'\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Fit the LightGBM model\n",
    "lgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"LightGBM Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_lgb))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93       687\n",
      "           1       0.19      0.50      0.27        34\n",
      "\n",
      "    accuracy                           0.87       721\n",
      "   macro avg       0.58      0.70      0.60       721\n",
      "weighted avg       0.94      0.87      0.90       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the CatBoost model with auto_class_weights\n",
    "cat_model = CatBoostClassifier(random_state=42, auto_class_weights='Balanced', verbose=0)\n",
    "\n",
    "# Fit the CatBoost model\n",
    "cat_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"CatBoost Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_cat))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'dt__max_depth': None, 'log__C': 0.01, 'rf__max_depth': None, 'rf__n_estimators': 50}\n",
      "Best cross-validation score:  0.9749884947865377\n",
      "Best Voting Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.89      0.93       687\n",
      "         yes       0.19      0.53      0.28        34\n",
      "\n",
      "    accuracy                           0.87       721\n",
      "   macro avg       0.58      0.71      0.60       721\n",
      "weighted avg       0.94      0.87      0.90       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for each model\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [None, 10, 20],\n",
    "    'dt__max_depth': [None, 10, 20],\n",
    "    'log__C': [0.01, 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Create the Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model),\n",
    "        ('log', log_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(voting_clf, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Print classification report for the best model\n",
    "print(\"Best Voting Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "### The model performs well in predicting the no class but struggles significantly with the yes class. The low precision and recall for yes suggest that improvements are needed to enhance the model’s ability to identify the minority class effectively."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'dt__max_depth': 20, 'gb__n_estimators': 200, 'log__C': 0.001, 'rf__max_depth': 20, 'rf__n_estimators': 100}\n",
      "Best cross-validation score:  0.9712791032992678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Oversampling with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a more comprehensive parameter grid\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200, 300],\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    'dt__max_depth': [None, 10, 20, 30],\n",
    "    'log__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'gb__n_estimators': [100, 200],\n",
    "}\n",
    "\n",
    "# Voting classifier with weighted estimators\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model),\n",
    "        ('log', log_model)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1, 2, 1, 1]  # Adjust weights based on prior performance\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV with a broader grid\n",
    "grid_search = GridSearchCV(voting_clf, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Check results\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
