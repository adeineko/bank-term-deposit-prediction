{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f183bd9",
   "metadata": {},
   "source": [
    "# Model Evaluation and Hyperparameter Tuning Project\n",
    "\n",
    "In this project, we evaluate multiple machine learning models on a classification task and employ techniques like resampling to handle class imbalance. We compare the models based on accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier  # Importing XGBClassifier\n",
    "import lightgbm as lgb  # Importing LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"../dataset/updated_bank.csv\");"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:46.917023Z",
     "start_time": "2024-11-01T16:18:45.876169Z"
    }
   },
   "id": "dcab12507cc45e8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "f34bc14b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The data is split into training and test sets. To handle class imbalance, we use **SMOTE combined with Edited Nearest Neighbors (ENN)**, an oversampling technique that creates synthetic samples and removes overlapping samples."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:46.933023Z",
     "start_time": "2024-11-01T16:18:46.918024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df.drop(\"y\", axis=1);\n",
    "y = df[\"y\"]\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    X[column] = label_enc.fit_transform(X[column])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ],
   "id": "3930d6f387554622",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a592fc0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:47.075088Z",
     "start_time": "2024-11-01T16:18:46.933023Z"
    }
   },
   "source": [
    "# Handle class imbalance using SMOTE combined with ENN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_res, y_train_res = smote_enn.fit_resample(X_train, y_train)\n",
    "print(f\"Resampled training set has {len(y_train_res)} samples with {sum(y_train_res == 1)} positives and {sum(y_train_res == 0)} negatives.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled training set has 2882 samples with 0 positives and 0 negatives.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "e460b7ea",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We initialize six models and train them on the resampled training data. The models include Random Forest, Gradient Boosting, Decision Tree, XGBoost, LightGBM, and CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "id": "ddefcf6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:48.454422Z",
     "start_time": "2024-11-01T16:18:47.076089Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Initialize models\n",
    "rf_model = RandomForestClassifier()\n",
    "gb_model = GradientBoostingClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "lgbm_model = LGBMClassifier()\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "\n",
    "# Fit models on resampled training set\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "gb_model.fit(X_train_res, y_train_res)\n",
    "dt_model.fit(X_train_res, y_train_res)\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "lgbm_model.fit(X_train_res, y_train_res)\n",
    "catboost_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Dictionary of models\n",
    "models = {\n",
    "    'Random Forest': rf_model,\n",
    "    'Gradient Boosting': gb_model,\n",
    "    'Decision Tree': dt_model,\n",
    "    'XGBoost': xgb_model,\n",
    "    'LightGBM': lgbm_model,\n",
    "    'CatBoost': catboost_model\n",
    "}"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['no' 'yes']",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 20\u001B[0m\n\u001B[0;32m     18\u001B[0m gb_model\u001B[38;5;241m.\u001B[39mfit(X_train_res, y_train_res)\n\u001B[0;32m     19\u001B[0m dt_model\u001B[38;5;241m.\u001B[39mfit(X_train_res, y_train_res)\n\u001B[1;32m---> 20\u001B[0m \u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_res\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_res\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m lgbm_model\u001B[38;5;241m.\u001B[39mfit(X_train_res, y_train_res)\n\u001B[0;32m     22\u001B[0m catboost_model\u001B[38;5;241m.\u001B[39mfit(X_train_res, y_train_res)\n",
      "File \u001B[1;32mD:\\KDG project\\machinelearning\\venv\\lib\\site-packages\\xgboost\\core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\KDG project\\machinelearning\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1491\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001B[0m\n\u001B[0;32m   1486\u001B[0m     expected_classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\n\u001B[0;32m   1487\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1488\u001B[0m     classes\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m expected_classes\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m   1489\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (classes \u001B[38;5;241m==\u001B[39m expected_classes)\u001B[38;5;241m.\u001B[39mall()\n\u001B[0;32m   1490\u001B[0m ):\n\u001B[1;32m-> 1491\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1492\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid classes inferred from unique values of `y`.  \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1493\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexpected_classes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclasses\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1494\u001B[0m     )\n\u001B[0;32m   1496\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_xgb_params()\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['no' 'yes']"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "952844e0",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We define a function to evaluate each model on the test set, calculating accuracy, precision, recall, and F1 score for the positive class. The results will help us compare each model's effectiveness after addressing class imbalance with SMOTE-ENN."
   ]
  },
  {
   "cell_type": "code",
   "id": "b695649d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:48.456424Z",
     "start_time": "2024-11-01T16:18:48.455428Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model_performance(models, X_test, y_test):\n",
    "    # Initialize a dictionary to store metrics for each model\n",
    "    performance_data = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision (Yes)': [],\n",
    "        'Recall (Yes)': [],\n",
    "        'F1 Score (Yes)': []\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Generate predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics with integer label for positive class\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "        # Append the metrics to the performance data\n",
    "        performance_data['Model'].append(model_name)\n",
    "        performance_data['Accuracy'].append(accuracy)\n",
    "        performance_data['Precision (Yes)'].append(precision)\n",
    "        performance_data['Recall (Yes)'].append(recall)\n",
    "        performance_data['F1 Score (Yes)'].append(f1)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame for easy viewing\n",
    "    performance_df = pd.DataFrame(performance_data)\n",
    "    return performance_df\n",
    "\n",
    "# Evaluate and display performance summary\n",
    "performance_summary = evaluate_model_performance(models, X_test, y_test)\n",
    "performance_summary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "299c89a7",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "After handling class imbalance with SMOTE-ENN, the models have become more capable of detecting the positive class. The following conclusions can be drawn:\n",
    "\n",
    "- **Accuracy** slightly decreased due to resampling but still remains relatively high.\n",
    "- **Recall** improved significantly across models, particularly in Gradient Boosting and LightGBM.\n",
    "- **Precision** is lower due to the trade-off with recall, which is expected with SMOTE-ENN.\n",
    "\n",
    "**LightGBM** and **CatBoost** offer the best balance of precision, recall, and F1 score.\n",
    "\n",
    "Further tuning of thresholds or ensembling may enhance precision while maintaining recall."
   ]
  },
  {
   "cell_type": "code",
   "id": "a9d76bfbd7b65ff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:48.457424Z",
     "start_time": "2024-11-01T16:18:48.457424Z"
    }
   },
   "source": [
    "# Model 1: Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "conf_matrix_random_forest = confusion_matrix(y_test, y_pred_rf);conf_matrix_random_forest"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3665796e4665586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:48.458423Z",
     "start_time": "2024-11-01T16:18:48.458423Z"
    }
   },
   "source": [
    "report_random_forest = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(report_random_forest)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b52fba68186b1273",
   "metadata": {},
   "source": [
    "# Model 2: Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "conf_matrix_gradient_boosting = confusion_matrix(y_test, y_pred_gb);conf_matrix_gradient_boosting"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e021b898e8686102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:48.460425Z",
     "start_time": "2024-11-01T16:18:48.459424Z"
    }
   },
   "source": [
    "report_gradient_boosting = classification_report(y_test, y_pred_gb)\n",
    "\n",
    "print(report_gradient_boosting)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a871b4ef",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:48.461424Z",
     "start_time": "2024-11-01T16:18:48.460425Z"
    }
   },
   "source": [
    "# Model 3: Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "conf_matrix_decision_tree = confusion_matrix(y_test, y_pred_dt)\n",
    "report_decision_tree = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Classifier Report:\")\n",
    "print(report_decision_tree)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9be7a9ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " # Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "id": "664e16e4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:48.461424Z",
     "start_time": "2024-11-01T16:18:48.461424Z"
    }
   },
   "source": [
    "# Create a Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model)\n",
    "    ],\n",
    "    voting='hard'  # Use 'soft' for probabilistic voting if desired\n",
    ")\n",
    "\n",
    "# Fit the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the Voting Classifier\n",
    "conf_matrix_voting = confusion_matrix(y_test, y_pred_voting)\n",
    "report_voting = classification_report(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Voting Classifier Report:\")\n",
    "print(report_voting)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "253cb99e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T16:18:48.462424Z",
     "start_time": "2024-11-01T16:18:48.462424Z"
    }
   },
   "source": [
    "\n",
    "# Create a Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()  # Meta-learner\n",
    ")\n",
    "\n",
    "# Fit the Stacking Classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the Stacking Classifier\n",
    "conf_matrix_stacking = confusion_matrix(y_test, y_pred_stacking)\n",
    "report_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "print(\"Stacking Classifier Report:\")\n",
    "print(report_stacking)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5775a451",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"../dataset/updated_bank.csv\")\n",
    "X = df.drop(\"y\", axis=1)\n",
    "y = df[\"y\"]\n",
    "\n",
    "# Label Encoding for categorical features\n",
    "label_enc = LabelEncoder()\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    X[column] = label_enc.fit_transform(X[column])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance using SMOTE combined with ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_res, y_train_res = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize models with class weights\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "dt_model = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "log_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "\n",
    "# Voting Classifier as an alternative ensemble method\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model),\n",
    "        ('log', log_model)\n",
    "    ],\n",
    "    voting='soft'  # Using soft voting to improve performance\n",
    ")\n",
    "\n",
    "# Fit the Voting Classifier\n",
    "voting_clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the Voting Classifier\n",
    "print(\"Voting Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf7de35c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert boolean columns to integer (0 and 1)\n",
    "X['contact_cellular'] = X['contact_cellular'].astype(int)\n",
    "X['contact_telephone'] = X['contact_telephone'].astype(int)\n",
    "X['contact_unknown'] = X['contact_unknown'].astype(int)\n",
    "\n",
    "# Label Encoding for categorical features in X (features)\n",
    "label_enc = LabelEncoder()\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    X[column] = label_enc.fit_transform(X[column])\n",
    "\n",
    "# Label encode the target variable y, if it's categorical (e.g., 'yes', 'no')\n",
    "if y.dtype == 'object':\n",
    "    y = label_enc.fit_transform(y)\n",
    "\n",
    "# Split the dataset after ensuring it's numeric\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance using SMOTE combined with ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_res, y_train_res = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the XGBoost model with scale_pos_weight to handle class imbalance\n",
    "pos_class_weight = (len(y_train_res) - sum(y_train_res)) / sum(y_train_res)\n",
    "xgb_model = XGBClassifier(random_state=42, scale_pos_weight=pos_class_weight)\n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3420e6b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the LightGBM model with class_weight='balanced'\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Fit the LightGBM model\n",
    "lgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"LightGBM Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_lgb))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c1df944",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the CatBoost model with auto_class_weights\n",
    "cat_model = CatBoostClassifier(random_state=42, auto_class_weights='Balanced', verbose=0)\n",
    "\n",
    "# Fit the CatBoost model\n",
    "cat_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"CatBoost Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_cat))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bbadc2e7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7ea360e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Define parameter grid for each model\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [None, 10, 20],\n",
    "    'dt__max_depth': [None, 10, 20],\n",
    "    'log__C': [0.01, 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Create the Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model),\n",
    "        ('log', log_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(voting_clf, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Print classification report for the best model\n",
    "print(\"Best Voting Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "086f655f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusion\n",
    "### The model performs well in predicting the no class but struggles significantly with the yes class. The low precision and recall for yes suggest that improvements are needed to enhance the modelâ€™s ability to identify the minority class effectively."
   ]
  },
  {
   "cell_type": "code",
   "id": "150dcb63",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Oversampling with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a more comprehensive parameter grid\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200, 300],\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    'dt__max_depth': [None, 10, 20, 30],\n",
    "    'log__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'gb__n_estimators': [100, 200],\n",
    "}\n",
    "\n",
    "# Voting classifier with weighted estimators\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('dt', dt_model),\n",
    "        ('log', log_model)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1, 2, 1, 1]  # Adjust weights based on prior performance\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV with a broader grid\n",
    "grid_search = GridSearchCV(voting_clf, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Check results\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f9558c96",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e451434",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "# Initialize models\n",
    "rf_model = RandomForestClassifier()\n",
    "gb_model = GradientBoostingClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "lgbm_model = LGBMClassifier()\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "\n",
    "# Fit models (assuming you have X_train, y_train)\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "gb_model.fit(X_train_res, y_train_res)\n",
    "dt_model.fit(X_train_res, y_train_res)\n",
    "xgb_model.fit(X_train_res,y_train_res)\n",
    "lgbm_model.fit(X_train_res, y_train_res)\n",
    "catboost_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Dictionary of models\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"Decision Tree\": dt_model,\n",
    "    \"XGBoost\": xgb_model,\n",
    "    \"LightGBM\": lgbm_model,\n",
    "    \"CatBoost\": catboost_model\n",
    "}\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model_performance(models, X_test, y_test):\n",
    "    # Initialize a dictionary to store metrics for each model\n",
    "    performance_data = {\n",
    "        \"Model\": [],\n",
    "        \"Accuracy\": [],\n",
    "        \"Precision (Yes)\": [],\n",
    "        \"Recall (Yes)\": [],\n",
    "        \"F1 Score (Yes)\": []\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Generate predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "        # Append the metrics to the performance data\n",
    "        performance_data[\"Model\"].append(model_name)\n",
    "        performance_data[\"Accuracy\"].append(accuracy)\n",
    "        performance_data[\"Precision (Yes)\"].append(precision)\n",
    "        performance_data[\"Recall (Yes)\"].append(recall)\n",
    "        performance_data[\"F1 Score (Yes)\"].append(f1)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame for easy viewing\n",
    "    performance_df = pd.DataFrame(performance_data)\n",
    "    return performance_df\n",
    "\n",
    "# Evaluate and display performance summary\n",
    "performance_summary = evaluate_model_performance(models, X_test, y_test)\n",
    "print(performance_summary)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
